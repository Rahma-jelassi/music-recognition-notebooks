{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c00c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: tensorflow-hub in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: librosa in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: soundfile in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from tensorflow-hub) (2.20.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (0.62.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (1.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: rich in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow) (0.18.0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from numba>=0.51.0->librosa) (0.45.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rahmaa\\desktop\\deep learning\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "‚úÖ Imports OK\n",
      "TensorFlow version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Installer les packages n√©cessaires\n",
    "!pip install tensorflow tensorflow-hub librosa soundfile\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Imports OK\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd40a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üéµ EXTRACTION EMBEDDINGS YAMNET - 1000 CHANSONS\n",
      "======================================================================\n",
      "\n",
      "üìÅ Dossier audio: C:\\Users\\Rahmaa\\Desktop\\deep learning\\downloadSongs\\audio_dataset_1000\n",
      "üíæ Dossier embeddings: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\n",
      "‚è±Ô∏è Dur√©e estim√©e: ~8-10 heures\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Configuration\n",
    "\n",
    "# CONFIGURATION - Chemins mis √† jour\n",
    "AUDIO_FOLDER = r\"C:\\Users\\Rahmaa\\Desktop\\deep learning\\downloadSongs\\audio_dataset_1000\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\"\n",
    "\n",
    "# Cr√©er le dossier des embeddings\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üéµ EXTRACTION EMBEDDINGS YAMNET - 1000 CHANSONS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Dossier audio: {AUDIO_FOLDER}\")\n",
    "print(f\"üíæ Dossier embeddings: {OUTPUT_DIR}\")\n",
    "print(f\"‚è±Ô∏è Dur√©e estim√©e: ~8-10 heures\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fa29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìÇ SCAN DES FICHIERS AUDIO\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Trouv√© 1000 fichiers audio\n",
      "\n",
      "üìã Exemples de fichiers:\n",
      "   1. Adele - Love In The Dark.m4a\n",
      "   2. Adele - Set Fire to the Rain.m4a\n",
      "   3. Adele - When We Were Young.m4a\n",
      "   4. aespa - aenergy.m4a\n",
      "   5. aespa - Dirty Work.m4a\n",
      "   6. aespa - Rich Man.m4a\n",
      "   7. aespa - UP (KARINA Solo).m4a\n",
      "   8. aespa - ÏûêÍ∞ÅÎ™Ω Lucid Dream.m4a\n",
      "   9. Angham - Aktablk Tahod.m4a\n",
      "   10. Angham - Ana Baatoh Kteer.m4a\n",
      "   ... et 990 autres fichiers\n",
      "\n",
      "‚úÖ Dataset: 1000 chansons pr√™tes\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Lister les Fichiers Audio\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìÇ SCAN DES FICHIERS AUDIO\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Extensions support√©es\n",
    "audio_extensions = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.webm', '.opus']\n",
    "\n",
    "# Trouver tous les fichiers audio\n",
    "audio_files = []\n",
    "for ext in audio_extensions:\n",
    "    audio_files.extend(list(Path(AUDIO_FOLDER).glob(f'*{ext}')))\n",
    "\n",
    "print(f\"‚úÖ Trouv√© {len(audio_files)} fichiers audio\\n\")\n",
    "\n",
    "if len(audio_files) == 0:\n",
    "    print(\"‚ùå AUCUN FICHIER TROUV√â!\")\n",
    "    print(f\"Place tes fichiers dans: {AUDIO_FOLDER}\")\n",
    "    raise FileNotFoundError(\"Aucun fichier audio trouv√©!\")\n",
    "\n",
    "# Afficher quelques exemples\n",
    "print(\"üìã Exemples de fichiers:\")\n",
    "for i, file in enumerate(audio_files[:10], 1):\n",
    "    print(f\"   {i}. {file.name}\")\n",
    "\n",
    "if len(audio_files) > 10:\n",
    "    print(f\"   ... et {len(audio_files) - 10} autres fichiers\")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset: {len(audio_files)} chansons pr√™tes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e75b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìù EXTRACTION DES M√âTADONN√âES\n",
      "======================================================================\n",
      "\n",
      "‚úÖ 1000 chansons index√©es\n",
      "\n",
      "üìä Aper√ßu des m√©tadonn√©es:\n",
      "   id  artist                  song\n",
      "0   0   Adele      Love In The Dark\n",
      "1   1   Adele  Set Fire to the Rain\n",
      "2   2   Adele    When We Were Young\n",
      "3   3   aespa               aenergy\n",
      "4   4   aespa            Dirty Work\n",
      "5   5   aespa              Rich Man\n",
      "6   6   aespa      UP (KARINA Solo)\n",
      "7   7   aespa       ÏûêÍ∞ÅÎ™Ω Lucid Dream\n",
      "8   8  Angham         Aktablk Tahod\n",
      "9   9  Angham      Ana Baatoh Kteer\n",
      "\n",
      "üìà Statistiques:\n",
      "   ‚Ä¢ Total chansons: 1000\n",
      "   ‚Ä¢ Artistes uniques: 52\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Extraction des M√©tadonn√©es\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìù EXTRACTION DES M√âTADONN√âES\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Cr√©er un DataFrame avec les infos\n",
    "songs_data = []\n",
    "\n",
    "for audio_file in audio_files:\n",
    "    filename = audio_file.stem \n",
    "    \n",
    "    # Parser \"Artist - Song\" \n",
    "    if ' - ' in filename:\n",
    "        parts = filename.split(' - ', 1)\n",
    "        artist = parts[0].strip()\n",
    "        song = parts[1].strip()\n",
    "    else:\n",
    "        artist = \"Unknown\"\n",
    "        song = filename\n",
    "    \n",
    "    songs_data.append({\n",
    "        'id': len(songs_data),\n",
    "        'filename': audio_file.name,\n",
    "        'filepath': str(audio_file),\n",
    "        'artist': artist,\n",
    "        'song': song\n",
    "    })\n",
    "\n",
    "df_songs = pd.DataFrame(songs_data)\n",
    "\n",
    "print(f\"‚úÖ {len(df_songs)} chansons index√©es\\n\")\n",
    "print(\"üìä Aper√ßu des m√©tadonn√©es:\")\n",
    "print(df_songs[['id', 'artist', 'song']].head(10))\n",
    "\n",
    "print(f\"\\nüìà Statistiques:\")\n",
    "print(f\"   ‚Ä¢ Total chansons: {len(df_songs)}\")\n",
    "print(f\"   ‚Ä¢ Artistes uniques: {df_songs['artist'].nunique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71344f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üß† CHARGEMENT DU MOD√àLE YAMNET\n",
      "======================================================================\n",
      "\n",
      "üì• T√©l√©chargement de YAMNet depuis TensorFlow Hub...\n",
      "(Premi√®re fois: ~1-2 minutes)\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ YAMNet charg√© avec succ√®s!\n",
      "\n",
      "üìä Info sur YAMNet:\n",
      "   ‚Ä¢ Architecture: CNN (MobileNet-like)\n",
      "   ‚Ä¢ Pr√©-entra√Æn√© sur: AudioSet (2M+ clips)\n",
      "   ‚Ä¢ Input: Audio 16kHz mono\n",
      "   ‚Ä¢ Output: Embeddings 1024D\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Charger le Mod√®le YAMNet\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üß† CHARGEMENT DU MOD√àLE YAMNET\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"üì• T√©l√©chargement de YAMNet depuis TensorFlow Hub...\")\n",
    "print(\"(Premi√®re fois: ~1-2 minutes)\\n\")\n",
    "\n",
    "# Charger YAMNet pr√©-entra√Æn√©\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "print(\"‚úÖ YAMNet charg√© avec succ√®s!\")\n",
    "print(\"\\nüìä Info sur YAMNet:\")\n",
    "print(\"   ‚Ä¢ Architecture: CNN (MobileNet-like)\")\n",
    "print(\"   ‚Ä¢ Pr√©-entra√Æn√© sur: AudioSet (2M+ clips)\")\n",
    "print(\"   ‚Ä¢ Input: Audio 16kHz mono\")\n",
    "print(\"   ‚Ä¢ Output: Embeddings 1024D\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction d'extraction d√©finie\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Fonction d'Extraction d'Embeddings\n",
    "\n",
    "def extract_yamnet_embedding(audio_path, duration=30):\n",
    "    \"\"\"\n",
    "    Extrait l'embedding YAMNet d'un fichier audio\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Chemin vers le fichier audio\n",
    "        duration: Dur√©e en secondes √† analyser (30s = signature suffisante)\n",
    "    \n",
    "    Returns:\n",
    "        embedding: Vector 1024D repr√©sentant l'audio\n",
    "        error_msg: Message d'erreur si √©chec\n",
    "    \"\"\"\n",
    "    try:\n",
    "        waveform = None\n",
    "        error_msg = None\n",
    "        \n",
    "        # M√©thode 1: librosa normal\n",
    "        try:\n",
    "            waveform, sr = librosa.load(audio_path, sr=16000, duration=duration, mono=True)\n",
    "        except Exception as e1:\n",
    "            # M√©thode 2: audioread\n",
    "            try:\n",
    "                import audioread\n",
    "                with audioread.audio_open(audio_path) as f:\n",
    "                    sr = f.samplerate\n",
    "                    duration_frames = int(duration * sr) if duration else None\n",
    "                    waveform = np.concatenate([np.frombuffer(buf, dtype=np.int16) \n",
    "                                              for buf in f])\n",
    "                    if duration_frames:\n",
    "                        waveform = waveform[:duration_frames]\n",
    "                    waveform = waveform.astype(np.float32) / 32768.0\n",
    "                    if sr != 16000:\n",
    "                        waveform = librosa.resample(waveform, orig_sr=sr, target_sr=16000)\n",
    "            except Exception as e2:\n",
    "                error_msg = f\"√âchec chargement: {Path(audio_path).name}\"\n",
    "                return None, error_msg\n",
    "        \n",
    "        if waveform is None or len(waveform) == 0:\n",
    "            return None, \"Waveform vide\"\n",
    "        \n",
    "        # Normaliser l'amplitude\n",
    "        if np.abs(waveform).max() > 0:\n",
    "            waveform = waveform / np.abs(waveform).max()\n",
    "        \n",
    "        # Extraire les embeddings avec YAMNet\n",
    "        scores, embeddings, spectrogram = yamnet_model(waveform)\n",
    "        \n",
    "        # Moyenner les embeddings sur toute la dur√©e\n",
    "        embedding = np.mean(embeddings.numpy(), axis=0)\n",
    "        \n",
    "        return embedding, None\n",
    "    \n",
    "    except Exception as e:\n",
    "        error_msg = f\"{Path(audio_path).name}: {str(e)[:50]}\"\n",
    "        return None, error_msg\n",
    "\n",
    "\n",
    "print(\"‚úÖ Fonction d'extraction d√©finie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3347d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéµ EXTRACTION DES EMBEDDINGS - 1000 CHANSONS\n",
      "======================================================================\n",
      "\n",
      "‚è±Ô∏è Dur√©e estim√©e: ~8-10 heures\n",
      "üí° Le script sauvegarde automatiquement tous les 100 fichiers\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:   0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\Rahmaa\\AppData\\Local\\Temp\\ipykernel_7592\\1773875211.py:24: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, sr = librosa.load(audio_path, sr=16000, duration=duration, mono=True)\n",
      "c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "üéµ Extraction:   0%|          | 1/1000 [00:04<1:15:51,  4.56s/it]C:\\Users\\Rahmaa\\AppData\\Local\\Temp\\ipykernel_7592\\1773875211.py:24: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  waveform, sr = librosa.load(audio_path, sr=16000, duration=duration, mono=True)\n",
      "c:\\Users\\Rahmaa\\Desktop\\deep learning\\.venv\\Lib\\site-packages\\librosa\\core\\audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "üéµ Extraction:  10%|‚ñà         | 100/1000 [00:26<03:01,  4.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 100/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 100\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 0.4 min\n",
      "   ‚è∞ Temps restant estim√©: 4.0 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_100.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  20%|‚ñà‚ñà        | 200/1000 [00:47<02:54,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 200/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 200\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 0.8 min\n",
      "   ‚è∞ Temps restant estim√©: 3.2 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_200.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  30%|‚ñà‚ñà‚ñà       | 300/1000 [01:10<03:23,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 300/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 300\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 1.2 min\n",
      "   ‚è∞ Temps restant estim√©: 2.7 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_300.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  40%|‚ñà‚ñà‚ñà‚ñà      | 400/1000 [01:33<02:20,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 400/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 400\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 1.6 min\n",
      "   ‚è∞ Temps restant estim√©: 2.3 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_400.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 500/1000 [01:55<01:51,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 500/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 500\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 1.9 min\n",
      "   ‚è∞ Temps restant estim√©: 1.9 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_500.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 600/1000 [02:18<01:24,  4.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 600/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 600\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 2.3 min\n",
      "   ‚è∞ Temps restant estim√©: 1.5 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_600.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 700/1000 [02:39<01:06,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 700/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 700\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 2.7 min\n",
      "   ‚è∞ Temps restant estim√©: 1.1 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_700.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 800/1000 [03:01<00:42,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 800/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 800\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 3.0 min\n",
      "   ‚è∞ Temps restant estim√©: 0.8 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_800.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 901/1000 [03:22<00:19,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 900/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 900\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 3.4 min\n",
      "   ‚è∞ Temps restant estim√©: 0.4 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_900.npy\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üéµ Extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [03:46<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   ‚úÖ 1000/1000 trait√©s\n",
      "   ‚úÖ Succ√®s: 1000\n",
      "   ‚ùå √âchecs: 0\n",
      "   ‚è±Ô∏è Temps √©coul√©: 3.8 min\n",
      "   ‚è∞ Temps restant estim√©: 0.0 min\n",
      "\n",
      "   üíæ Sauvegarde temp: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\embeddings_temp_1000.npy\n",
      "\n",
      "\n",
      "======================================================================\n",
      "‚úÖ EXTRACTION TERMIN√âE!\n",
      "======================================================================\n",
      "üìä Shape des embeddings: (1000, 1024)\n",
      "‚úÖ Succ√®s: 1000/1000\n",
      "‚è±Ô∏è Temps total: 3.8 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Extraction des Embeddings - BATCH PROCESSING\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéµ EXTRACTION DES EMBEDDINGS - 1000 CHANSONS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"‚è±Ô∏è Dur√©e estim√©e: ~8-10 heures\")\n",
    "print(f\"üí° Le script sauvegarde automatiquement tous les 100 fichiers\\n\")\n",
    "\n",
    "# Initialisation\n",
    "embeddings_list = []\n",
    "failed_files = []\n",
    "error_details = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Traiter par batch avec sauvegarde r√©guli√®re\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "for idx, row in tqdm(df_songs.iterrows(), total=len(df_songs), desc=\"üéµ Extraction\"):\n",
    "    # Extraire embedding\n",
    "    embedding, error_msg = extract_yamnet_embedding(row['filepath'], duration=30)\n",
    "    \n",
    "    if embedding is not None:\n",
    "        embeddings_list.append(embedding)\n",
    "    else:\n",
    "        embeddings_list.append(np.zeros(1024))  # Embedding vide si √©chec\n",
    "        failed_files.append(row['filename'])\n",
    "        if error_msg:\n",
    "            error_details.append(error_msg)\n",
    "    \n",
    "    # Sauvegarde interm√©diaire tous les 100 fichiers\n",
    "    if (idx + 1) % BATCH_SIZE == 0:\n",
    "        elapsed = (datetime.now() - start_time).total_seconds() / 60\n",
    "        remaining = ((len(df_songs) - idx - 1) / (idx + 1)) * elapsed\n",
    "        \n",
    "        print(f\"\\n   ‚úÖ {idx + 1}/{len(df_songs)} trait√©s\")\n",
    "        print(f\"   ‚úÖ Succ√®s: {(idx + 1) - len(failed_files)}\")\n",
    "        print(f\"   ‚ùå √âchecs: {len(failed_files)}\")\n",
    "        print(f\"   ‚è±Ô∏è Temps √©coul√©: {elapsed:.1f} min\")\n",
    "        print(f\"   ‚è∞ Temps restant estim√©: {remaining:.1f} min\\n\")\n",
    "        \n",
    "        # Sauvegarde interm√©diaire\n",
    "        temp_embeddings = np.array(embeddings_list)\n",
    "        temp_path = os.path.join(OUTPUT_DIR, f\"embeddings_temp_{idx+1}.npy\")\n",
    "        np.save(temp_path, temp_embeddings)\n",
    "        print(f\"   üíæ Sauvegarde temp: {temp_path}\\n\")\n",
    "\n",
    "# Convertir en array final\n",
    "embeddings_array = np.array(embeddings_list)\n",
    "\n",
    "# Temps total\n",
    "total_time = (datetime.now() - start_time).total_seconds() / 60\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ EXTRACTION TERMIN√âE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"üìä Shape des embeddings: {embeddings_array.shape}\")\n",
    "print(f\"‚úÖ Succ√®s: {len(df_songs) - len(failed_files)}/{len(df_songs)}\")\n",
    "print(f\"‚è±Ô∏è Temps total: {total_time:.1f} minutes\")\n",
    "\n",
    "if failed_files:\n",
    "    print(f\"\\n‚ö†Ô∏è {len(failed_files)} fichiers √©chou√©s:\")\n",
    "    for f in failed_files[:10]:\n",
    "        print(f\"   ‚Ä¢ {f}\")\n",
    "    if len(failed_files) > 10:\n",
    "        print(f\"   ... et {len(failed_files) - 10} autres\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e8441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üíæ SAUVEGARDE DE LA DATABASE\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Embeddings: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\audio_embeddings_yamnet_1000.npy\n",
      "   Shape: (1000, 1024)\n",
      "   Taille: 3.91 MB\n",
      "\n",
      "‚úÖ M√©tadonn√©es: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\songs_metadata_1000.csv\n",
      "   1000 chansons\n",
      "\n",
      "‚úÖ Configuration: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\database_config.pkl\n",
      "‚úÖ Rapport: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\\extraction_report.txt\n",
      "\n",
      "======================================================================\n",
      "üéâ DATABASE CR√â√âE AVEC SUCC√àS!\n",
      "======================================================================\n",
      "\n",
      "üìÅ Dossier: C:\\Users\\Rahmaa\\Desktop\\deep learning\\audio_embeddings_database\n",
      "\n",
      "üì¶ Fichiers cr√©√©s:\n",
      "   1. audio_embeddings_yamnet_1000.npy ((1000, 1024))\n",
      "   2. songs_metadata_1000.csv (1000 chansons)\n",
      "   3. database_config.pkl\n",
      "   4. extraction_report.txt\n",
      "\n",
      "üéØ Prochaine √©tape:\n",
      "   ‚Üí Utiliser ces embeddings pour reconnaissance en temps r√©el\n",
      "   ‚Üí Comparer avec audio enregistr√© via cosine similarity\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Sauvegarde Finale de la Database\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üíæ SAUVEGARDE DE LA DATABASE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# 1. Sauvegarder les embeddings\n",
    "embeddings_path = os.path.join(OUTPUT_DIR, \"audio_embeddings_yamnet_1000.npy\")\n",
    "np.save(embeddings_path, embeddings_array)\n",
    "print(f\"‚úÖ Embeddings: {embeddings_path}\")\n",
    "print(f\"   Shape: {embeddings_array.shape}\")\n",
    "print(f\"   Taille: {embeddings_array.nbytes / (1024**2):.2f} MB\")\n",
    "\n",
    "# 2. Sauvegarder les m√©tadonn√©es\n",
    "metadata_path = os.path.join(OUTPUT_DIR, \"songs_metadata_1000.csv\")\n",
    "df_songs.to_csv(metadata_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n‚úÖ M√©tadonn√©es: {metadata_path}\")\n",
    "print(f\"   {len(df_songs)} chansons\")\n",
    "\n",
    "# 3. Sauvegarder la configuration\n",
    "config = {\n",
    "    'n_songs': len(df_songs),\n",
    "    'embedding_dim': 1024,\n",
    "    'model': 'YAMNet',\n",
    "    'duration_seconds': 30,\n",
    "    'sample_rate': 16000,\n",
    "    'creation_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    'failed_files': failed_files,\n",
    "    'processing_time_minutes': total_time\n",
    "}\n",
    "\n",
    "config_path = os.path.join(OUTPUT_DIR, \"database_config.pkl\")\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(config, f)\n",
    "print(f\"\\n‚úÖ Configuration: {config_path}\")\n",
    "\n",
    "# 4. Sauvegarder rapport texte\n",
    "report_path = os.path.join(OUTPUT_DIR, \"extraction_report.txt\")\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"RAPPORT D'EXTRACTION EMBEDDINGS YAMNET\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(f\"Date: {config['creation_date']}\\n\")\n",
    "    f.write(f\"Total chansons: {len(df_songs)}\\n\")\n",
    "    f.write(f\"Succ√®s: {len(df_songs) - len(failed_files)}\\n\")\n",
    "    f.write(f\"√âchecs: {len(failed_files)}\\n\")\n",
    "    f.write(f\"Temps total: {total_time:.1f} minutes\\n\\n\")\n",
    "    \n",
    "    if failed_files:\n",
    "        f.write(\"Fichiers √©chou√©s:\\n\")\n",
    "        for file in failed_files:\n",
    "            f.write(f\"  - {file}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Rapport: {report_path}\")\n",
    "\n",
    "# R√©sum√© final\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ DATABASE CR√â√âE AVEC SUCC√àS!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìÅ Dossier: {OUTPUT_DIR}\")\n",
    "print(f\"\\nüì¶ Fichiers cr√©√©s:\")\n",
    "print(f\"   1. audio_embeddings_yamnet_1000.npy ({embeddings_array.shape})\")\n",
    "print(f\"   2. songs_metadata_1000.csv ({len(df_songs)} chansons)\")\n",
    "print(f\"   3. database_config.pkl\")\n",
    "print(f\"   4. extraction_report.txt\")\n",
    "print(\"\\nüéØ Prochaine √©tape:\")\n",
    "print(\"   ‚Üí Utiliser ces embeddings pour reconnaissance en temps r√©el\")\n",
    "print(\"   ‚Üí Comparer avec audio enregistr√© via cosine similarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a468f1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä VALIDATION DE LA DATABASE\n",
      "======================================================================\n",
      "\n",
      "Embeddings valides: 1000/1000\n",
      "\n",
      "üìà Statistiques des embeddings:\n",
      "   ‚Ä¢ Min: 0.0000\n",
      "   ‚Ä¢ Max: 7.0994\n",
      "   ‚Ä¢ Mean: 0.0732\n",
      "   ‚Ä¢ Std: 0.1620\n",
      "\n",
      "üé§ Top 10 Artistes:\n",
      "   877x NA\n",
      "     9x Angham\n",
      "     8x SEVENTEEN\n",
      "     6x PNL\n",
      "     6x TWICE\n",
      "     6x Red Velvet\n",
      "     5x Arctic Monkeys\n",
      "     5x TOMORROW X TOGETHER\n",
      "     5x aespa\n",
      "     4x Haifa Wehbe\n",
      "\n",
      "‚úÖ Validation termin√©e!\n",
      "\n",
      "üéµ Ta database de 1000 chansons est pr√™te pour Shazam-like!\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Statistiques et Validation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä VALIDATION DE LA DATABASE\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# V√©rifier qu'il n'y a pas d'embeddings nuls\n",
    "zero_embeddings = np.sum(np.all(embeddings_array == 0, axis=1))\n",
    "print(f\"Embeddings valides: {len(embeddings_array) - zero_embeddings}/{len(embeddings_array)}\")\n",
    "\n",
    "# Statistiques sur les embeddings\n",
    "print(f\"\\nüìà Statistiques des embeddings:\")\n",
    "print(f\"   ‚Ä¢ Min: {embeddings_array.min():.4f}\")\n",
    "print(f\"   ‚Ä¢ Max: {embeddings_array.max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {embeddings_array.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Std: {embeddings_array.std():.4f}\")\n",
    "\n",
    "# Top artistes\n",
    "print(f\"\\nüé§ Top 10 Artistes:\")\n",
    "top_artists = df_songs['artist'].value_counts().head(10)\n",
    "for artist, count in top_artists.items():\n",
    "    print(f\"   {count:3d}x {artist}\")\n",
    "\n",
    "print(\"\\n‚úÖ Validation termin√©e!\")\n",
    "print(\"\\nüéµ Ta database de 1000 chansons est pr√™te pour Shazam-like!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
